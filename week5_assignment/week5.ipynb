{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe900c82",
   "metadata": {},
   "source": [
    "# Ames Housing Price Prediction Pipeline\n",
    "\n",
    "This notebook walks through data preprocessing, feature engineering, and a linear regression model for predicting house prices using the Ames Housing dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413a2bb",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "Import necessary libraries for data handling, modeling, and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb998fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a816de",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Read training, test, and sample submission files from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87ca3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f0d72",
   "metadata": {},
   "source": [
    "## Prepare Features and Target\n",
    "- Separate the target variable `SalePrice` and IDs.\n",
    "- Drop them from feature sets to prepare for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3f47016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target and IDs\n",
    "y = train['SalePrice']\n",
    "train_ids = train['Id']\n",
    "test_ids = test['Id']\n",
    "\n",
    "# Drop unwanted columns\n",
    "train_features = train.drop(['SalePrice', 'Id'], axis=1)\n",
    "test_features = test.drop(['Id'], axis=1)\n",
    "\n",
    "# Combine for uniform preprocessing\n",
    "all_data = pd.concat([train_features, test_features], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e4561",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Create new composite features:\n",
    "- Total square footage (`TotalSF`)\n",
    "- Total porch area (`TotalPorchSF`)\n",
    "- Combined bathroom count (`TotalBath`)\n",
    "- House age, remodel age, and garage age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff4e95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\AppData\\Local\\Temp\\ipykernel_30256\\958614731.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_data['GarageAge'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Composite features\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "all_data['TotalPorchSF'] = all_data[['OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch']].sum(axis=1)\n",
    "all_data['TotalBath'] = (all_data['FullBath'] + 0.5*all_data['HalfBath'] +\n",
    "                         all_data['BsmtFullBath'] + 0.5*all_data['BsmtHalfBath'])\n",
    "all_data['HouseAge'] = all_data['YrSold'] - all_data['YearBuilt']\n",
    "all_data['RemodelAge'] = all_data['YrSold'] - all_data['YearRemodAdd']\n",
    "all_data['GarageAge'] = all_data['YrSold'] - all_data['GarageYrBlt']\n",
    "all_data['GarageAge'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72035983",
   "metadata": {},
   "source": [
    "## Split Back into Train/Test\n",
    "Separate the combined data back into training and test sets, and log-transform the target for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd4ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "n_train = y.shape[0]\n",
    "X_train = all_data.iloc[:n_train, :].copy()\n",
    "X_test = all_data.iloc[n_train:, :].copy()\n",
    "\n",
    "# Log-transform the target\n",
    "y_log = np.log1p(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d07e9",
   "metadata": {},
   "source": [
    "## Preprocessing Pipelines\n",
    "Define numeric and categorical transformers and combine them using `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b243aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature types\n",
    "numeric_feats = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_feats = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Numeric pipeline: impute and scale\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline: impute and one-hot encode\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine into ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_feats),\n",
    "    ('cat', categorical_transformer, categorical_feats)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d8ad8",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation\n",
    "- Build a full pipeline with preprocessing and `LinearRegression`.\n",
    "- Evaluate using 5-fold cross-validated RMSE on the log-transformed target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa20d86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE (log-target): 0.1572\n"
     ]
    }
   ],
   "source": [
    "# Full modeling pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Cross-validated RMSE (log-target)\n",
    "cv_scores = np.sqrt(-cross_val_score(\n",
    "    model_pipeline, X_train, y_log, cv=5, scoring='neg_mean_squared_error'\n",
    "))\n",
    "print(f'CV RMSE (log-target): {cv_scores.mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436194c3",
   "metadata": {},
   "source": [
    "## Train Final Model and Create Submission\n",
    "Train on the full training data, generate predictions on the test set, and prepare the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b489de84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Fit on full data\n",
    "model_pipeline.fit(X_train, y_log)\n",
    "\n",
    "# Predict and invert log-transform\n",
    "preds_log = model_pipeline.predict(X_test)\n",
    "preds = np.expm1(preds_log)\n",
    "\n",
    "# Prepare submission- This changes the sample's SalePrice to the predictions\n",
    "submission['SalePrice'] = preds\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Saved submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
